import streamlit as st
import os
from config_model import RAGConfig
from rag_engine import ConstructionRAG

# í˜ì´ì§€ ì„¤ì •
st.set_page_config(page_title="Kainexa ê±´ì„¤ë²•ë ¹ RAG", layout="wide")

# ë°ì´í„° ê²½ë¡œ (ì„œë²„ í™˜ê²½ì— ë§ê²Œ ìˆ˜ì • í•„ìš”)
BASE_DIR = os.getcwd() # í˜„ì¬ í´ë” ê¸°ì¤€
DATA_FILE = os.path.join(BASE_DIR, "data", "chunks_tonghap.jsonl") # í†µí•© ì²­í‚¹ íŒŒì¼
GLOSSARY_FILE = os.path.join(BASE_DIR, "data", "construction_law_glossary.csv")

# ---------------------------------------------------------
# ì‹œìŠ¤í…œ ì´ˆê¸°í™” (ìºì‹±í•˜ì—¬ ë¦¬ì†ŒìŠ¤ ì¬ì‚¬ìš©)
# ---------------------------------------------------------
@st.cache_resource
def get_system():
    # ë°ì´í„° íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸ìš© ê°€ë“œ
    if not os.path.exists(DATA_FILE):
        st.error(f"ë°ì´í„° íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤: {DATA_FILE}")
        return None
    
    st.info("RAG ì—”ì§„ì„ ì´ˆê¸°í™” ì¤‘ì…ë‹ˆë‹¤... (ëª¨ë¸ ë¡œë”©)")
    rag = ConstructionRAG(DATA_FILE, GLOSSARY_FILE)
    return rag

system = get_system()

# ---------------------------------------------------------
# UI Layout
# ---------------------------------------------------------
st.title("ğŸ—ï¸ Kainexa Construction Law RAG")
st.caption("ê±´ì„¤ë²•ë ¹/íŒë¡€/ì˜ê²°ì„œ í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì‹œìŠ¤í…œ")

# [ì‚¬ì´ë“œë°”] ì„¤ì • ì»¨íŠ¸ë¡¤
with st.sidebar:
    st.header("âš™ï¸ ê²€ìƒ‰ íŒŒë¼ë¯¸í„° ì„¤ì •")
    
    st.subheader("1. ê²€ìƒ‰ ë²”ìœ„")
    top_k = st.slider("ê²€ìƒ‰ ë¬¸ì„œ ìˆ˜ (Top-k)", 1, 20, 5)
    
    st.subheader("2. ê³ ê¸‰ ê¸°ëŠ¥ On/Off")
    use_glossary = st.toggle("ìš©ì–´ì§‘(Glossary) í™•ì¥", value=True, help="ì „ë¬¸ ìš©ì–´ ë™ì˜ì–´ í™•ì¥")
    use_graph = st.toggle("Graph DB(Neo4j) ì—°ê²°", value=False, help="ê´€ë ¨ ì¡°í•­/ì°¸ì¡° ì¡°í•­ íƒìƒ‰")
    use_rerank = st.toggle("Re-ranker ì ìš©", value=True, help="ì •ë°€ë„ í–¥ìƒì„ ìœ„í•œ ì¬ì •ë ¬")
    
    st.subheader("3. ê²°ê³¼ í•„í„°ë§")
    blend = st.slider("Reranker ë°˜ì˜ ë¹„ìœ¨", 0.0, 1.0, 0.8)

    # Config ê°ì²´ ìƒì„±
    config = RAGConfig(
        top_k=top_k,
        use_glossary=use_glossary,
        use_graph_db=use_graph,
        use_reranker=use_rerank,
        alpha_blend=blend
    )
    
    if st.button("ì„¤ì • ì ìš© ë° ì´ˆê¸°í™”"):
        st.cache_data.clear()
        st.success("ì„¤ì •ì´ ì ìš©ë˜ì—ˆìŠµë‹ˆë‹¤.")

# [ë©”ì¸] ì±„íŒ… ì¸í„°í˜ì´ìŠ¤
if "messages" not in st.session_state:
    st.session_state.messages = []

for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.write(msg["content"])
        if "context" in msg:
            with st.expander("ì°¸ê³  ë¬¸ì„œ í™•ì¸"):
                for idx, doc in enumerate(msg["context"], 1):
                    score_display = f"(Re-rank: {doc.get('rerank_score',0):.2f})" if use_rerank else f"(Fused: {doc.get('fused_score',0):.2f})"
                    st.markdown(f"**{idx}. [{doc.get('law_name')}] {doc.get('clause_id')}** {score_display}")
                    st.text(doc.get('text')[:200] + "...")

if prompt := st.chat_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš” (ì˜ˆ: í•˜ë„ê¸‰ ëŒ€ê¸ˆ ì§€ê¸‰ ë³´ì¦ ì˜ˆì™¸ ì‚¬ìœ ëŠ”?)"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.write(prompt)

    if system:
        with st.chat_message("assistant"):
            with st.spinner("ë²•ë ¹ ë¶„ì„ ë° ê²€ìƒ‰ ì¤‘..."):
                # ì—”ì§„ ì‹¤í–‰
                results, graph_info = system.run_pipeline(prompt, config)
                
                # ë‹µë³€ ìƒì„± (í˜„ì¬ëŠ” ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½ í˜•íƒœë¡œ í‘œì‹œ, LLM ì—°ê²° ê°€ëŠ¥)
                if not results:
                    response_text = "ê´€ë ¨ëœ ë²•ë ¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                else:
                    top_doc = results[0]
                    response_text = f"**[{top_doc.get('law_name')}] {top_doc.get('clause_id')}** ë‚´ìš©ì„ ê¸°ë°˜ìœ¼ë¡œ ë‹µë³€í•©ë‹ˆë‹¤.\n\n"
                    response_text += top_doc.get('text')
                    
                    if graph_info:
                        response_text += f"\n\nğŸ’¡ **ì§€ì‹ê·¸ë˜í”„ ì°¸ê³ :** {graph_info[:150]}..."

                st.markdown(response_text)
                
                # ê·¼ê±° ë¬¸ì„œ í‘œì‹œ
                with st.expander("ğŸ” ê²€ìƒ‰ëœ ê·¼ê±° ë¬¸ì„œ (Evidence)"):
                    for i, doc in enumerate(results, 1):
                        st.markdown(f"--- \n**{i}. {doc.get('title', 'ë¬¸ì„œ')}**")
                        st.caption(f"Score: {doc.get('rerank_score', 0):.4f}")
                        st.write(doc.get('text'))

            # ëŒ€í™” ê¸°ë¡ ì €ì¥
            st.session_state.messages.append({
                "role": "assistant", 
                "content": response_text,
                "context": results
            })
    else:
        st.error("ì‹œìŠ¤í…œì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ë°ì´í„° íŒŒì¼ ê²½ë¡œë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”.")