# src/core/orchestration/step_executors.py
"""ëª¨ë“  Step Executor í†µí•©"""
from typing import Dict, Any, List, Optional
from abc import ABC, abstractmethod
import asyncio
from datetime import datetime
import structlog

from src.nlp.korean_nlp import KoreanNLPPipeline
from src.governance.vector_store import VectorStore
from src.models.model_factory import ModelFactory

logger = structlog.get_logger()

class BaseExecutor(ABC):
    """ì‹¤í–‰ì ë² ì´ìŠ¤ í´ë˜ìŠ¤"""
    
    @abstractmethod
    async def execute(self, context: Dict[str, Any]) -> Any:
        pass

class IntentClassifyExecutor(BaseExecutor):
    """ì˜ë„ ë¶„ë¥˜ ì‹¤í–‰ì"""
    
    def __init__(self):
        self.nlp_pipeline = KoreanNLPPipeline()
    
    async def execute(self, context: Dict[str, Any]) -> Dict:
        text = context.get('input_text', '')
        result = await self.nlp_pipeline.process(text)
        
        return {
            'intent': result.intent,
            'entities': result.entities,
            'honorific_level': result.honorific_level.value,
            'sentiment': result.sentiment
        }

class RetrieveKnowledgeExecutor(BaseExecutor):
    """ì§€ì‹ ê²€ìƒ‰ ì‹¤í–‰ì"""
    
    def __init__(self):
        self.vector_store = VectorStore()
    
    async def execute(self, context: Dict[str, Any]) -> List[Dict]:
        query = context.get('query', context.get('input_text', ''))
        k = context.get('k', 5)
        
        results = await self.vector_store.search(query, k)
        
        # Re-ranking ì ìš©
        if len(results) > 1:
            results = self._rerank(query, results)
        
        return results
    
    def _rerank(self, query: str, results: List[Dict]) -> List[Dict]:
        """ê²°ê³¼ ì¬ìˆœìœ„í™”"""
        # Cross-encoder ì‚¬ìš© (ê°„ë‹¨ êµ¬í˜„)
        for result in results:
            # ì¿¼ë¦¬ì™€ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ì¬ê³„ì‚°
            result['rerank_score'] = result.get('score', 0.0) * 0.8
        
        return sorted(results, key=lambda x: x['rerank_score'], reverse=True)

class LLMGenerateExecutor(BaseExecutor):
    """LLM ìƒì„± ì‹¤í–‰ì"""
    
    def __init__(self):
        self.model_factory = ModelFactory()
        self.llm = None
    
    async def execute(self, context: Dict[str, Any]) -> str:
        # ëª¨ë¸ ì´ˆê¸°í™” (lazy loading)
        if not self.llm:
            model_type = context.get('model', 'solar')
            self.llm = self.model_factory.create_model(model_type)
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = self._build_prompt(context)
        
        # ìƒì„± íŒŒë¼ë¯¸í„°
        params = {
            'temperature': context.get('temperature', 0.7),
            'max_tokens': context.get('max_tokens', 512),
            'top_p': context.get('top_p', 0.9)
        }
        
        # LLM ìƒì„±
        response = await self.llm.generate(prompt, **params)
        
        return response

    def _build_prompt(self, context: Dict[str, Any]) -> str:
        """í”„ë¡¬í”„íŠ¸ êµ¬ì„±"""
        template = context.get('prompt_template', '')
        
        # ê¸°ë³¸ í…œí”Œë¦¿
        if not template:
            template = """ë‹¹ì‹ ì€ ë„ì›€ì´ ë˜ëŠ” AI ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
            
ì‚¬ìš©ì: {input_text}

{knowledge}

ì‘ë‹µ:"""
        
        # ì»¨í…ìŠ¤íŠ¸ ë³€ìˆ˜ë¡œ ì¹˜í™˜
        prompt = template
        
        # ì…ë ¥ í…ìŠ¤íŠ¸
        prompt = prompt.replace('{input_text}', context.get('input_text', ''))
        
        # RAG ê²°ê³¼ ì¶”ê°€
        if 'retrieved_knowledge' in context:
            knowledge_text = "\nê´€ë ¨ ì •ë³´:\n"
            for i, doc in enumerate(context['retrieved_knowledge'][:3], 1):
                knowledge_text += f"{i}. {doc.get('text', '')}\n"
            prompt = prompt.replace('{knowledge}', knowledge_text)
        else:
            prompt = prompt.replace('{knowledge}', '')
        
        # ëŒ€í™” ì´ë ¥ ì¶”ê°€
        if 'conversation_history' in context:
            history = context['conversation_history'][-5:]  # ìµœê·¼ 5ê°œ
            history_text = "\nì´ì „ ëŒ€í™”:\n"
            for h in history:
                history_text += f"ì‚¬ìš©ì: {h.get('user', '')}\n"
                history_text += f"AI: {h.get('assistant', '')}\n"
            prompt = history_text + "\n" + prompt
        
        return prompt

class MCPExecutionExecutor(BaseExecutor):
    """MCP ì•¡ì…˜ ì‹¤í–‰ì"""
    
    def __init__(self):
        self.action_registry = self._init_actions()
    
    def _init_actions(self) -> Dict:
        """ì•¡ì…˜ ë ˆì§€ìŠ¤íŠ¸ë¦¬ ì´ˆê¸°í™”"""
        return {
            'send_email': self._send_email,
            'create_ticket': self._create_ticket,
            'update_database': self._update_database,
            'call_api': self._call_external_api
        }
    
    async def execute(self, context: Dict[str, Any]) -> Dict:
        action_type = context.get('action_type')
        
        if not action_type:
            return {'status': 'skipped', 'reason': 'No action required'}
        
        # ê¶Œí•œ í™•ì¸
        if not self._check_permission(context):
            return {'status': 'denied', 'reason': 'Insufficient permissions'}
        
        # ì•¡ì…˜ ì‹¤í–‰
        if action_type in self.action_registry:
            result = await self.action_registry[action_type](context)
            return result
        
        return {'status': 'error', 'reason': f'Unknown action: {action_type}'}
    
    def _check_permission(self, context: Dict) -> bool:
        """ê¶Œí•œ í™•ì¸"""
        user_role = context.get('user_role', 'user')
        action_type = context.get('action_type')
        
        # ê°„ë‹¨í•œ ê¶Œí•œ ë§¤íŠ¸ë¦­ìŠ¤
        permissions = {
            'user': [],
            'agent': ['send_email', 'create_ticket'],
            'admin': ['send_email', 'create_ticket', 'update_database', 'call_api']
        }
        
        return action_type in permissions.get(user_role, [])
    
    async def _send_email(self, context: Dict) -> Dict:
        """ì´ë©”ì¼ ë°œì†¡"""
        logger.info("Sending email", context=context)
        # ì‹¤ì œ ì´ë©”ì¼ ë°œì†¡ ë¡œì§
        await asyncio.sleep(0.5)  # ì‹œë®¬ë ˆì´ì…˜
        return {'status': 'sent', 'message_id': 'email_12345'}
    
    async def _create_ticket(self, context: Dict) -> Dict:
        """í‹°ì¼“ ìƒì„±"""
        logger.info("Creating ticket", context=context)
        # í‹°ì¼“ ì‹œìŠ¤í…œ ì—°ë™
        return {'status': 'created', 'ticket_id': 'TICK-001'}
    
    async def _update_database(self, context: Dict) -> Dict:
        """ë°ì´í„°ë² ì´ìŠ¤ ì—…ë°ì´íŠ¸"""
        logger.info("Updating database", context=context)
        # DB ì—…ë°ì´íŠ¸ ë¡œì§
        return {'status': 'updated', 'affected_rows': 1}
    
    async def _call_external_api(self, context: Dict) -> Dict:
        """ì™¸ë¶€ API í˜¸ì¶œ"""
        import httpx
        
        url = context.get('api_url')
        method = context.get('api_method', 'GET')
        payload = context.get('api_payload', {})
        
        async with httpx.AsyncClient() as client:
            response = await client.request(method, url, json=payload)
            
        return {
            'status': 'completed',
            'status_code': response.status_code,
            'response': response.json() if response.status_code == 200 else None
        }

class ResponsePostprocessExecutor(BaseExecutor):
    """ì‘ë‹µ í›„ì²˜ë¦¬ ì‹¤í–‰ì"""
    
    def __init__(self):
        self.nlp_pipeline = KoreanNLPPipeline()
    
    async def execute(self, context: Dict[str, Any]) -> str:
        response = context.get('llm_response', '')
        
        # 1. ì¡´ëŒ“ë§ ë³€í™˜
        target_honorific = context.get('target_honorific')
        if target_honorific:
            nlp_result = await self.nlp_pipeline.process(response, target_honorific)
            response = nlp_result.text
        
        # 2. ì¶œì²˜ ì¶”ê°€
        if 'retrieved_knowledge' in context:
            sources = []
            for doc in context['retrieved_knowledge'][:3]:
                source = doc.get('metadata', {}).get('source', 'Unknown')
                if source not in sources:
                    sources.append(source)
            
            if sources:
                response += f"\n\nì¶œì²˜: {', '.join(sources)}"
        
        # 3. í¬ë§·íŒ…
        response = self._format_response(response)
        
        return response
    
    def _format_response(self, text: str) -> str:
        """ì‘ë‹µ í¬ë§·íŒ…"""
        # ë§ˆí¬ë‹¤ìš´ ì²˜ë¦¬
        text = text.strip()
        
        # ì´ëª¨ì§€ ì¶”ê°€ (ì„ íƒì )
        if 'ì£„ì†¡' in text:
            text = 'ğŸ˜” ' + text
        elif 'ê°ì‚¬' in text:
            text = 'ğŸ˜Š ' + text
        
        return text

# Executor ë ˆì§€ìŠ¤íŠ¸ë¦¬
EXECUTOR_REGISTRY = {
    'intent_classify': IntentClassifyExecutor,
    'retrieve_knowledge': RetrieveKnowledgeExecutor,
    'llm_generate': LLMGenerateExecutor,
    'mcp_execution': MCPExecutionExecutor,
    'response_postprocess': ResponsePostprocessExecutor
}

def create_executor(step_type: str) -> BaseExecutor:
    """ì‹¤í–‰ì ìƒì„± íŒ©í† ë¦¬"""
    executor_class = EXECUTOR_REGISTRY.get(step_type)
    if not executor_class:
        raise ValueError(f"Unknown executor type: {step_type}")
    return executor_class()