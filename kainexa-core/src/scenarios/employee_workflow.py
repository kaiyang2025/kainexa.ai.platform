# src/scenarios/employee_workflow.py
"""
ì§ì› Aì˜ ì—…ë¬´ ì—°ì†ì„± ì‹œë‚˜ë¦¬ì˜¤ êµ¬í˜„
"""
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import asyncio
import json
from dataclasses import dataclass

from src.orchestration.dsl_parser import DSLParser
from src.orchestration.graph_executor import GraphExecutor, ExecutionContext
from src.auth.mcp_permissions import MCPAuthManager, Role, Resource, Permission
from src.governance.rag_pipeline import RAGGovernance, AccessLevel
from src.models.tensor_parallel import TensorParallelSolarLLM

@dataclass
class EmployeeSession:
    """ì§ì› ì„¸ì…˜ ê´€ë¦¬"""
    employee_id: str
    name: str
    role: str
    department: str
    last_activity: datetime
    context_history: List[Dict[str, Any]]
    current_task: Optional[str] = None
    preferences: Dict[str, Any] = None

class AgenticWorkflowManager:
    """Agentic AI ì›Œí¬í”Œë¡œìš° ë§¤ë‹ˆì €"""
    
    def __init__(self):
        # í•µì‹¬ ì»´í¬ë„ŒíŠ¸
        self.auth_manager = MCPAuthManager(secret_key="kainexa-secret")
        self.rag_governance = RAGGovernance()
        self.llm = TensorParallelSolarLLM()
        
        # ì„¸ì…˜ ê´€ë¦¬ (ì‹¤ì œë¡œëŠ” Redis ì‚¬ìš©)
        self.sessions: Dict[str, EmployeeSession] = {}
        
        # ì›Œí¬í”Œë¡œìš° DSL
        self.workflow_dsl = self._load_workflow_dsl()
        
    def _load_workflow_dsl(self) -> str:
        """ì›Œí¬í”Œë¡œìš° DSL ì •ì˜"""
        return """
        name: employee_continuation_workflow
        version: "1.0"
        
        policies:
          session_timeout: 86400  # 24ì‹œê°„
          context_window: 10  # ìµœê·¼ 10ê°œ ëŒ€í™” ìœ ì§€
          
        graph:
          # 1. ì§ì› ì¸ì¦ ë° ì‹ë³„
          - step: authenticate_employee
            type: auth_check
            params:
              verify_token: true
              load_profile: true
            policy:
              if: "not authenticated"
              then:
                action: redirect_login
                
          # 2. ì´ì „ ì»¨í…ìŠ¤íŠ¸ ë³µì›
          - step: restore_context
            type: context_retrieval
            params:
              load_history: true
              load_last_task: true
              load_preferences: true
            cache: true
            
          # 3. ì‘ì—… ì˜ë„ íŒŒì•…
          - step: classify_intent
            type: intent_classify
            params:
              model: "solar-10.7b"
              use_context: true
              
          # 4. RAG ê¸°ë°˜ ì •ë³´ ê²€ìƒ‰
          - step: retrieve_information
            type: rag_retrieval
            params:
              sources: ["sales_reports", "internal_docs"]
              time_filter: "last_month"
              access_level: "employee"
            policy:
              if: "intent == 'sales_inquiry'"
              then:
                retrieve_specific: "sales_metrics"
                
          # 5. LLM ì‘ë‹µ ìƒì„±
          - step: generate_response
            type: llm_generate
            params:
              model: "solar-10.7b"
              temperature: 0.3
              use_rag_context: true
              use_session_context: true
              prompt_template: |
                ë‹¹ì‹ ì€ {employee_name}ë‹˜ì˜ ì—…ë¬´ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
                
                ì´ì „ ì‘ì—… ì»¨í…ìŠ¤íŠ¸:
                {previous_context}
                
                í˜„ì¬ ì§ˆë¬¸: {current_query}
                
                ê´€ë ¨ ì •ë³´ (RAG):
                {rag_results}
                
                ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”.
                
          # 6. MCP ì•¡ì…˜ ì‹¤í–‰
          - step: execute_actions
            type: mcp_execution
            params:
              check_permissions: true
              audit_log: true
            policy:
              if: "requires_action"
              then:
                validate_permission: true
                execute_with_confirmation: true
                
          # 7. ì»¨í…ìŠ¤íŠ¸ ì—…ë°ì´íŠ¸
          - step: update_context
            type: context_update
            params:
              save_interaction: true
              update_task_status: true
              update_preferences: true
        """
        
    async def handle_employee_interaction(self, 
                                         employee_id: str,
                                         message: str,
                                         token: str) -> Dict[str, Any]:
        """ì§ì› ìƒí˜¸ì‘ìš© ì²˜ë¦¬"""
        
        # 1. ì§ì› ì¸ì¦ ë° ì„¸ì…˜ í™•ì¸
        employee_session = await self._authenticate_and_load_session(
            employee_id, token
        )
        
        # 2. ì´ì „ ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ë³µì›
        context = await self._restore_context(employee_session)
        
        # 3. í˜„ì¬ ë©”ì‹œì§€ ì²˜ë¦¬
        response = await self._process_message(
            employee_session,
            message,
            context
        )
        
        # 4. ì„¸ì…˜ ì—…ë°ì´íŠ¸
        await self._update_session(employee_session, message, response)
        
        return response
    
    async def _authenticate_and_load_session(self, 
                                            employee_id: str,
                                            token: str) -> EmployeeSession:
        """ì§ì› ì¸ì¦ ë° ì„¸ì…˜ ë¡œë“œ"""
        
        # MCP í† í° ê²€ì¦
        token_payload = self.auth_manager.verify_token(token)
        
        # ê¸°ì¡´ ì„¸ì…˜ í™•ì¸
        if employee_id in self.sessions:
            session = self.sessions[employee_id]
            
            # ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ ì²´í¬
            if (datetime.now() - session.last_activity).seconds < 86400:
                print(f"âœ… ì§ì› {session.name}ë‹˜, ë‹¤ì‹œ ì˜¤ì…¨ë„¤ìš”!")
                session.last_activity = datetime.now()
                return session
        
        # ìƒˆ ì„¸ì…˜ ìƒì„±
        session = EmployeeSession(
            employee_id=employee_id,
            name=token_payload.metadata.get('name', 'Unknown'),
            role=token_payload.role.value,
            department=token_payload.metadata.get('department', 'General'),
            last_activity=datetime.now(),
            context_history=[],
            preferences={}
        )
        
        self.sessions[employee_id] = session
        print(f"ğŸ‘‹ ìƒˆë¡œìš´ ì„¸ì…˜ ìƒì„±: {session.name}ë‹˜")
        
        return session
    
    async def _restore_context(self, 
                              session: EmployeeSession) -> Dict[str, Any]:
        """ì´ì „ ì‘ì—… ì»¨í…ìŠ¤íŠ¸ ë³µì›"""
        
        context = {
            'employee_name': session.name,
            'department': session.department,
            'last_task': session.current_task,
            'history': []
        }
        
        # ìµœê·¼ ëŒ€í™” ë‚´ì—­ (ìµœëŒ€ 10ê°œ)
        if session.context_history:
            recent_history = session.context_history[-10:]
            context['history'] = recent_history
            
            # ë§ˆì§€ë§‰ ì‘ì—… ìš”ì•½
            last_interaction = recent_history[-1]
            context['last_interaction'] = {
                'timestamp': last_interaction.get('timestamp'),
                'query': last_interaction.get('query'),
                'task': last_interaction.get('task')
            }
            
            print(f"ğŸ“ ì´ì „ ì‘ì—… ë³µì›: {session.current_task}")
            
        return context
    
    async def _process_message(self,
                              session: EmployeeSession,
                              message: str,
                              context: Dict[str, Any]) -> Dict[str, Any]:
        """ë©”ì‹œì§€ ì²˜ë¦¬ ë° ì‘ë‹µ ìƒì„±"""
        
        print(f"ğŸ’¬ ì²˜ë¦¬ ì¤‘: {message}")
        
        # ì˜ë„ íŒŒì•…
        intent = await self._classify_intent(message, context)
        
        response = {
            'timestamp': datetime.now().isoformat(),
            'intent': intent,
            'rag_results': None,
            'llm_response': None,
            'actions': []
        }
        
        # RAG ê²€ìƒ‰ í•„ìš” ì—¬ë¶€ í™•ì¸
        if self._needs_rag_retrieval(intent, message):
            print("ğŸ” RAGì—ì„œ ì •ë³´ ê²€ìƒ‰ ì¤‘...")
            
            # ì§€ë‚œë‹¬ ë§¤ì¶œ ì •ë³´ ë“± ê²€ìƒ‰
            rag_results = await self._retrieve_from_rag(
                message, 
                session,
                time_filter="last_month"
            )
            response['rag_results'] = rag_results
            
            # ê²€ìƒ‰ ê²°ê³¼ ìš”ì•½
            if rag_results:
                print(f"ğŸ“Š {len(rag_results)}ê°œ ê´€ë ¨ ë¬¸ì„œ ë°œê²¬")
        
        # LLM ì‘ë‹µ ìƒì„±
        llm_response = await self._generate_llm_response(
            message,
            context,
            response.get('rag_results'),
            session
        )
        response['llm_response'] = llm_response
        
        # MCP ì•¡ì…˜ ì‹¤í–‰ í•„ìš” í™•ì¸
        if self._needs_mcp_action(intent, message):
            print("âš¡ MCP ì•¡ì…˜ ì‹¤í–‰...")
            
            actions = await self._execute_mcp_actions(
                intent,
                message,
                session
            )
            response['actions'] = actions
        
        return response
    
    async def _classify_intent(self, 
                              message: str,
                              context: Dict[str, Any]) -> str:
        """ì˜ë„ ë¶„ë¥˜"""
        
        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ê¸°ë°˜ ë¶„ë¥˜ (ì‹¤ì œë¡œëŠ” ML ëª¨ë¸ ì‚¬ìš©)
        intent_keywords = {
            'sales_inquiry': ['ë§¤ì¶œ', 'íŒë§¤', 'ì‹¤ì ', 'ìˆ˜ìµ'],
            'task_continuation': ['ì–´ì œ', 'ì´ì „', 'ê³„ì†', 'ì´ì–´ì„œ'],
            'report_generation': ['ë³´ê³ ì„œ', 'ë¦¬í¬íŠ¸', 'ì‘ì„±', 'ë¬¸ì„œ'],
            'data_analysis': ['ë¶„ì„', 'í†µê³„', 'ì°¨íŠ¸', 'ê·¸ë˜í”„'],
            'action_request': ['ì‹¤í–‰', 'ì²˜ë¦¬', 'ì§„í–‰', 'ìˆ˜í–‰']
        }
        
        for intent, keywords in intent_keywords.items():
            if any(keyword in message for keyword in keywords):
                return intent
                
        return 'general_inquiry'
    
    def _needs_rag_retrieval(self, intent: str, message: str) -> bool:
        """RAG ê²€ìƒ‰ í•„ìš” ì—¬ë¶€"""
        rag_intents = ['sales_inquiry', 'data_analysis', 'report_generation']
        rag_keywords = ['ì •ë³´', 'ë°ì´í„°', 'ìë£Œ', 'ë¬¸ì„œ', 'ë§¤ì¶œ', 'ì‹¤ì ']
        
        return (intent in rag_intents or 
                any(keyword in message for keyword in rag_keywords))
    
    async def _retrieve_from_rag(self,
                                message: str,
                                session: EmployeeSession,
                                time_filter: str = None) -> List[Dict[str, Any]]:
        """RAGì—ì„œ ì •ë³´ ê²€ìƒ‰"""
        
        # ì ‘ê·¼ ê¶Œí•œ ë ˆë²¨ ê²°ì •
        access_level = AccessLevel.INTERNAL
        if session.role in ['admin', 'manager']:
            access_level = AccessLevel.CONFIDENTIAL
            
        # í•„í„° ì„¤ì •
        filters = {}
        if time_filter == "last_month":
            last_month = datetime.now() - timedelta(days=30)
            filters['created_after'] = last_month.isoformat()
            
        # RAG ê²€ìƒ‰
        results = await self.rag_governance.retrieve(
            query=message,
            k=5,
            user_access_level=access_level,
            filters=filters
        )
        
        return results
    
    async def _generate_llm_response(self,
                                    message: str,
                                    context: Dict[str, Any],
                                    rag_results: Optional[List[Dict]],
                                    session: EmployeeSession) -> str:
        """LLM ì‘ë‹µ ìƒì„±"""
        
        # í”„ë¡¬í”„íŠ¸ êµ¬ì„±
        prompt = f"""
        ë‹¹ì‹ ì€ {session.name}ë‹˜ì˜ ì—…ë¬´ ì–´ì‹œìŠ¤í„´íŠ¸ì…ë‹ˆë‹¤.
        ë¶€ì„œ: {session.department}
        ì—­í• : {session.role}
        
        ì´ì „ ì‘ì—…: {session.current_task or 'ì—†ìŒ'}
        ë§ˆì§€ë§‰ ëŒ€í™”: {context.get('last_interaction', {}).get('query', 'ì—†ìŒ')}
        
        í˜„ì¬ ì§ˆë¬¸: {message}
        """
        
        if rag_results:
            prompt += "\n\nê´€ë ¨ ì •ë³´:\n"
            for i, result in enumerate(rag_results[:3], 1):
                prompt += f"{i}. {result.get('text', '')}\n"
                prompt += f"   ì¶œì²˜: {result.get('source', '')}\n"
        
        prompt += "\nìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì ì ˆí•œ ì‘ë‹µì„ ìƒì„±í•˜ì„¸ìš”."
        
        # LLM ìƒì„±
        response = await self.llm.generate(
            prompt=prompt,
            max_length=512,
            temperature=0.3
        )
        
        return response['text']
    
    def _needs_mcp_action(self, intent: str, message: str) -> bool:
        """MCP ì•¡ì…˜ í•„ìš” ì—¬ë¶€"""
        action_intents = ['action_request', 'report_generation']
        action_keywords = ['ì‹¤í–‰', 'ì²˜ë¦¬', 'ìƒì„±', 'ë§Œë“¤ì–´', 'ë³´ë‚´']
        
        return (intent in action_intents or 
                any(keyword in message for keyword in action_keywords))
    
    async def _execute_mcp_actions(self,
                                  intent: str,
                                  message: str,
                                  session: EmployeeSession) -> List[Dict[str, Any]]:
        """MCP ì•¡ì…˜ ì‹¤í–‰"""
        
        actions = []
        
        # ê¶Œí•œ í™•ì¸
        can_execute = self.auth_manager.check_permission(
            session,
            Resource.ACTION,
            Permission.EXECUTE
        )
        
        if not can_execute:
            actions.append({
                'type': 'permission_denied',
                'message': 'í•´ë‹¹ ì‘ì—…ì„ ì‹¤í–‰í•  ê¶Œí•œì´ ì—†ìŠµë‹ˆë‹¤.'
            })
            return actions
        
        # ì•¡ì…˜ íƒ€ì…ë³„ ì²˜ë¦¬
        if 'ë³´ê³ ì„œ' in message:
            actions.append({
                'type': 'generate_report',
                'status': 'initiated',
                'details': 'ì›”ê°„ ë§¤ì¶œ ë³´ê³ ì„œ ìƒì„± ì¤‘...'
            })
            
        elif 'ì´ë©”ì¼' in message:
            actions.append({
                'type': 'send_email',
                'status': 'prepared',
                'details': 'ì´ë©”ì¼ ì´ˆì•ˆ ì‘ì„± ì™„ë£Œ'
            })
            
        elif 'ë¶„ì„' in message:
            actions.append({
                'type': 'data_analysis',
                'status': 'processing',
                'details': 'ë°ì´í„° ë¶„ì„ ì§„í–‰ ì¤‘...'
            })
        
        return actions
    
    async def _update_session(self,
                             session: EmployeeSession,
                             message: str,
                             response: Dict[str, Any]):
        """ì„¸ì…˜ ì—…ë°ì´íŠ¸"""
        
        # ëŒ€í™” ê¸°ë¡ ì¶”ê°€
        session.context_history.append({
            'timestamp': response['timestamp'],
            'query': message,
            'response': response['llm_response'],
            'intent': response['intent'],
            'has_rag': response['rag_results'] is not None,
            'has_actions': len(response['actions']) > 0
        })
        
        # í˜„ì¬ ì‘ì—… ì—…ë°ì´íŠ¸
        if response['intent'] == 'task_continuation':
            session.current_task = f"Continuing: {message[:50]}..."
        elif response['intent'] in ['report_generation', 'data_analysis']:
            session.current_task = f"Working on: {response['intent']}"
            
        # ë§ˆì§€ë§‰ í™œë™ ì‹œê°„ ì—…ë°ì´íŠ¸
        session.last_activity = datetime.now()
        
        print(f"ğŸ’¾ ì„¸ì…˜ ì—…ë°ì´íŠ¸ ì™„ë£Œ")


# ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ì˜ˆì œ
async def run_scenario():
    """ì§ì› A ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰"""
    
    print("=" * 60)
    print("Kainexa AI Agent Platform - Employee Workflow Scenario")
    print("=" * 60)
    
    # ì›Œí¬í”Œë¡œìš° ë§¤ë‹ˆì € ì´ˆê¸°í™”
    manager = AgenticWorkflowManager()
    
    # ì§ì› A í† í° ìƒì„± (ì²« ë¡œê·¸ì¸)
    token = manager.auth_manager.create_token(
        user_id="employee_a",
        role=Role.AGENT,
        permissions=None
    )
    
    print("\n[Day 1 - ì²« ì‘ì—…]")
    print("-" * 40)
    
    # Day 1: ì²« ì‘ì—…
    response1 = await manager.handle_employee_interaction(
        employee_id="employee_a",
        message="ì§€ë‚œë‹¬ ë§¤ì¶œ ì •ë³´ë¥¼ ë¶„ì„í•´ì¤˜",
        token=token
    )
    
    print(f"Intent: {response1['intent']}")
    print(f"RAG ê²€ìƒ‰: {'Yes' if response1['rag_results'] else 'No'}")
    print(f"Response: {response1['llm_response'][:200]}...")
    
    await asyncio.sleep(1)
    
    print("\n[Day 2 - ì‘ì—… ì—°ì†]")
    print("-" * 40)
    
    # Day 2: ì–´ì œ ì‘ì—… ì´ì–´ê°€ê¸°
    response2 = await manager.handle_employee_interaction(
        employee_id="employee_a",
        message="ì–´ì œ ë¶„ì„í•˜ë˜ ë§¤ì¶œ ì •ë³´ë¥¼ ì´ì–´ì„œ ë³´ê³ ì„œë¡œ ë§Œë“¤ì–´ì¤˜",
        token=token
    )
    
    print(f"ì´ì „ ì‘ì—… ì¸ì‹: Yes")
    print(f"Intent: {response2['intent']}")
    print(f"MCP Actions: {response2['actions']}")
    print(f"Response: {response2['llm_response'][:200]}...")
    
    print("\nâœ… ì‹œë‚˜ë¦¬ì˜¤ ì‹¤í–‰ ì™„ë£Œ!")
    print("=" * 60)


if __name__ == "__main__":
    asyncio.run(run_scenario())