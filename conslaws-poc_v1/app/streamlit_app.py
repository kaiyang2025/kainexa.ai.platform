# -*- coding: utf-8 -*-
"""
streamlit_app.py (Demo UI Revision)
- ê±´ì„¤í˜‘íšŒ ì‹œì—°ìš© ê²€ìƒ‰ ì¤‘ì‹¬ UI
- ë‹¤ì‹œ ì‹œì‘
- ì£¼ìš” ë³€ê²½: í†µí•© ê²€ìƒ‰ íë¦„, ì¹´ë“œí˜• UI, ì„¤ì • ìˆ¨ê¹€, ìŠ¤íŠ¸ë¦¬ë° íš¨ê³¼
"""
from __future__ import annotations

import os
import time
import httpx
import streamlit as st
import pandas as pd

# ---------------------------- ì„¤ì • & ìŠ¤íƒ€ì¼ ----------------------------
API_DEFAULT = os.environ.get("API_URL", "http://localhost:8000")
API = st.secrets.get("API_URL", API_DEFAULT)

st.set_page_config(
    page_title="ê±´ì„¤ ë²•ë ¹ AI ê°€ì´ë“œ",
    page_icon="ğŸ—ï¸",
    layout="wide",
    initial_sidebar_state="collapsed"
)

# ì»¤ìŠ¤í…€ CSS
st.markdown("""
<style>
    .main-title { font-size: 2.5rem; font-weight: 700; color: #2C3E50; margin-bottom: 0.5rem; }
    .sub-title { font-size: 1.2rem; color: #7F8C8D; margin-bottom: 2rem; }
    .answer-box { background-color: #ffffff; border-left: 5px solid #27ae60; padding: 20px; border-radius: 5px; box-shadow: 0 2px 5px rgba(0,0,0,0.05); }
    section[data-testid="stSidebar"] { background-color: #f0f2f6; }
</style>
""", unsafe_allow_html=True)

# ---------------------------- ìœ í‹¸ í•¨ìˆ˜ ----------------------------
def call_full_process(query: str, k: int, rerank: bool, cand_factor: float, backend: str, model: str):
    try:
        payload = {
            "query": query, "k": k, "rerank": rerank, "include_context": True,
            "gen_backend": backend, "gen_model": model, "cand_factor": cand_factor,
        }
        with st.spinner("ë²•ë ¹ì„ ë¶„ì„í•˜ê³  ë‹µë³€ì„ ìƒì„± ì¤‘ì…ë‹ˆë‹¤..."):
            t0 = time.perf_counter()
            resp = httpx.post(f"{API}/answer", json=payload, timeout=120)
            resp.raise_for_status()
            data = resp.json()
            t1 = time.perf_counter()
        return data, (t1 - t0)
    except Exception as e:
        st.error(f"ì‹œìŠ¤í…œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        return None, 0.0

def stream_text(text: str):
    for word in text.split(" "):
        yield word + " "
        time.sleep(0.02)

# ---------------------------- ì‚¬ì´ë“œë°” ----------------------------
with st.sidebar:
    st.header("âš™ï¸ ê´€ë¦¬ì ì„¤ì •")
    with st.expander("ê²€ìƒ‰/ëª¨ë¸ ì˜µì…˜", expanded=False):
        k_val = st.slider("Top-k", 3, 20, 6)
        rerank_val = st.checkbox("ë¦¬ë­í¬ ì ìš©", value=True)
        cand_factor_val = st.slider("í›„ë³´êµ° ë°°ìˆ˜", 1.0, 5.0, 2.0, 0.1)
        st.divider()
        gen_backend = st.selectbox("ìƒì„± ë°±ì—”ë“œ", ["openai", "dummy"], index=0)
        gen_model = st.text_input("ëª¨ë¸ëª…", value="gpt-4o-mini")

# ---------------------------- ë©”ì¸ UI ----------------------------
st.markdown('<div class="main-title">ğŸ—ï¸ ê±´ì„¤ ë²•ë ¹ AI ê°€ì´ë“œ</div>', unsafe_allow_html=True)
st.markdown('<div class="sub-title">ê±´ì„¤ì‚°ì—…ê¸°ë³¸ë²• ë° í•˜ë„ê¸‰ë²• ê´€ë ¨ ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”.</div>', unsafe_allow_html=True)

with st.form("search_form"):
    col1, col2 = st.columns([5, 1])
    with col1:
        query = st.text_input("ì§ˆë¬¸ ì…ë ¥", placeholder="ì˜ˆ) í•˜ë„ê¸‰ëŒ€ê¸ˆ ì§ì ‘ì§€ê¸‰ ìš”ê±´ì€?", label_visibility="collapsed")
    with col2:
        # [ìˆ˜ì •] ê²½ê³  í•´ê²°: use_container_width -> type='primary'ë¡œ ê°•ì¡° (ë„ˆë¹„ ìë™)
        # ë§Œì•½ ê½‰ ì±„ìš°ê³  ì‹¶ë‹¤ë©´ width íŒŒë¼ë¯¸í„°ê°€ ì§€ì›ë˜ì§€ ì•ŠëŠ” êµ¬ë²„ì „ì¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ use_container_width=True ìœ ì§€í•˜ë˜ ê²½ê³  ë¬´ì‹œ
        # ì—¬ê¸°ì„œëŠ” ìµœì‹  ê¶Œì¥ì‚¬í•­ ë°˜ì˜ ì‹œë„:
        submit = st.form_submit_button("ğŸ” ê²€ìƒ‰", type="primary", use_container_width=True)

if submit and query:
    result_data, latency = call_full_process(query, k_val, rerank_val, cand_factor_val, gen_backend, gen_model)
    
    if result_data:
        answer_text = result_data.get("answer", "")
        contexts = result_data.get("contexts") or []
        
        st.divider()
        st.subheader("ğŸ’¡ AI ë‹µë³€")
        answer_container = st.empty()
        
        if gen_backend == "dummy":
            st.warning("âš ï¸ Dummy ëª¨ë“œì…ë‹ˆë‹¤.")
            answer_container.markdown(f'<div class="answer-box">{answer_text}</div>', unsafe_allow_html=True)
        else:
            streamed_output = ""
            for token in stream_text(answer_text):
                streamed_output += token
                answer_container.markdown(f'<div class="answer-box">{streamed_output}</div>', unsafe_allow_html=True)
        
        st.caption(f"â±ï¸ {latency:.2f}ì´ˆ | ë¬¸ì„œ: {len(contexts)}ê±´")
        
        st.subheader("ğŸ“š ê·¼ê±° ë²•ë ¹")
        if not contexts:
            st.info("ì°¸ì¡°ëœ ë²•ë ¹ì´ ì—†ìŠµë‹ˆë‹¤.")
        else:
            top_contexts = contexts[:4]
            cols = st.columns(2)
            
            for i, ctx in enumerate(top_contexts):
                law = ctx.get('law_name', 'ë²•ë ¹')
                clause = ctx.get('clause_id', '')
                title = ctx.get('title', '')
                # [ìˆ˜ì •] None ì•ˆì „ ì²˜ë¦¬
                text = ctx.get('text') or "" 
                score = ctx.get('score', 0)
                short_text = text[:150] + "..." if len(text) > 150 else text
                
                with cols[i % 2]:
                    with st.container(border=True):
                        st.markdown(f"**ğŸ“„ {law} {clause}**")
                        if title: st.caption(f"{title}")
                        st.markdown(f"{short_text}")
                        st.caption(f"ê´€ë ¨ë„: {score:.4f}")

        with st.expander("ğŸ§ ì „ì²´ ë¬¸ë§¥ ìƒì„¸ë³´ê¸°"):
            if contexts:
                df = pd.DataFrame(contexts)
                display_cols = ["law_name", "clause_id", "title", "score", "text"]
                final_cols = [c for c in display_cols if c in df.columns]
                st.dataframe(df[final_cols], use_container_width=True, hide_index=True)
            else:
                st.write("ë°ì´í„° ì—†ìŒ")