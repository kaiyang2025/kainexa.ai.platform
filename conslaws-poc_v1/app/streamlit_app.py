import streamlit as st
import httpx
import json, math, time
import pandas as pd


API = st.secrets.get("API_URL", "http://localhost:8000")

st.set_page_config(page_title="ê±´ì„¤ë²•ë ¹ RAG POC", layout="wide")
st.title("ğŸ—ï¸ ê±´ì„¤ë²•ë ¹ RAG POC (v2)")

# === Sidebar: ë¦¬ë­í¬ í›„ë³´í­ ì„¤ì • ===
st.sidebar.markdown("### ê²€ìƒ‰/ë¦¬ë­í¬ ì„¤ì •")
# cand_factor: ë¦¬ë­ì»¤ì— íƒœìš¸ í›„ë³´ ìˆ˜ë¥¼ kì˜ ëª‡ ë°°ë¡œ í• ì§€ (ì˜ˆ: 2.0ì´ë©´ Top-2kë¥¼ ë¦¬ë­í¬)
cand_factor = st.sidebar.slider("ë¦¬ë­í¬ í›„ë³´í­ (cand_factor Ã— k)", 1.0, 5.0, 2.0, 0.5)
st.sidebar.caption("ì˜ˆ) Top-k=8, cand_factor=2.0 â†’ ìƒìœ„ 16ê°œë¥¼ ë¦¬ë­í¬")

# ===================== Eval helpers (ê°„ë‹¨ ë©”íŠ¸ë¦­ ê³„ì‚°) ======================
def _dcg_at_k(rels, k=10):
    return sum(rel / math.log2(i + 2) for i, rel in enumerate(rels[:k]))
def _ndcg_at_k(pred_ids, gold_ids, k=10):
    rels = [1 if pid in gold_ids else 0 for pid in pred_ids[:k]]
    idcg = 1.0  # ë‹¨ì¼ ì •ë‹µ ê°€ì •
    return (_dcg_at_k(rels, k) / idcg) if idcg > 0 else 0.0
def _mrr_at_k(pred_ids, gold_ids, k=10):
    for i, pid in enumerate(pred_ids[:k], start=1):
        if pid in gold_ids: return 1.0 / i
    return 0.0
def _recall_at_k(pred_ids, gold_ids, k=10):
    return 1.0 if any(pid in gold_ids for pid in pred_ids[:k]) else 0.0
def _p95(values):
    if not values: return 0.0
    s = sorted(values); idx = max(0, min(int(math.ceil(0.95*len(s))) - 1, len(s)-1))
    return s[idx]
def _load_eval_jsonl(uploaded_file):
    items = []
    for raw in uploaded_file:
        line = raw.decode("utf-8") if isinstance(raw,(bytes,bytearray)) else raw
        if not line.strip(): continue
        row = json.loads(line)
        q = row.get("query"); gold_ids = row.get("gold_ids"); gold_id = row.get("gold_id")
        if gold_ids is None: gold_ids = [gold_id] if gold_id else []
        if q: items.append({"query": q, "gold_ids": [g for g in gold_ids if g]})
    return items
# ========================================================================

# =========================== Tabs: ê²€ìƒ‰ / í‰ê°€ ===========================
tab_search, tab_eval = st.tabs(["ê²€ìƒ‰", "í‰ê°€(Eval)"])

with tab_search:
    q = st.text_input("ì§ˆë¬¸ì„ ì…ë ¥í•˜ì„¸ìš”", value="ë°œì£¼ìì˜ ê³µì‚¬ëŒ€ê¸ˆ ì§€ê¸‰ë³´ì¦ ì˜ë¬´ëŠ”?")
    c1, c2, c3, c4 = st.columns(4)
    with c1: k = st.number_input("Top-K", min_value=3, max_value=20, value=8, step=1)
    with c2: rerank = st.checkbox("Rerank ì‚¬ìš©", value=True)
    with c3: backend = st.selectbox("ìƒì„± ë°±ì—”ë“œ", ["openai","dummy"], index=1)
    with c4: model = st.text_input("ëª¨ë¸", value="gpt-4o-mini")

    if st.button("ê²€ìƒ‰/ë‹µë³€ ì‹¤í–‰", use_container_width=True):
        with st.spinner("ê²€ìƒ‰ ì¤‘..."):
            sr = httpx.get(
                f"{API}/search",
                params={"q": q, "k": k, "rerank": str(rerank).lower(), "cand_factor": cand_factor},
                timeout=120,
            ).json()
        st.subheader("ğŸ” ê²€ìƒ‰ ê²°ê³¼ (ìƒìœ„)")
        for i, h in enumerate(sr["results"], 1):
            with st.expander(f"{i}. [{h['law_name']}] {h['clause_id']} â€” {h.get('title','')[:40]}"):
                st.write(h["text"])

        with st.spinner("ìƒì„± ì¤‘..."):
            ar = httpx.post(
                f"{API}/answer",
                json={
                    "query": q, "k": k, "rerank": rerank, "include_context": True,
                    "gen_backend": backend, "gen_model": model, "cand_factor": cand_factor,
                },
                timeout=180,
            ).json()
        st.subheader("ğŸ§  ë‹µë³€")
        st.write(ar["answer"])
        st.caption("ê·¼ê±° ì¸ìš©: " + ", ".join([f"[{c['law']} {c['clause_id']}]" for c in ar["citations"]]))
        st.divider()
        st.subheader("ğŸ“š ì»¨í…ìŠ¤íŠ¸")
        for i, c in enumerate(ar.get("contexts", []), 1):
            with st.expander(f"{i}. [{c['law_name']}] {c['clause_id']} â€” {c.get('title','')[:40]}"):
                st.write(c["text"])

with tab_eval:
    st.subheader("RAG ê²€ìƒ‰ í’ˆì§ˆ/ì§€ì—° í‰ê°€")
    st.caption("eval.jsonl ì—…ë¡œë“œ â†’ nDCG@10 / MRR@10 / Recall@10 / P95 latency ê³„ì‚°")
    up = st.file_uploader("í‰ê°€ì…‹ íŒŒì¼ ì—…ë¡œë“œ (eval.jsonl)", type=["jsonl"])
    ec1, ec2, ec3 = st.columns(3)
    with ec1: ek = st.number_input("Top-k", min_value=1, max_value=50, value=10, step=1)
    with ec2: ererank = st.checkbox("ë¦¬ë­í¬ ì‚¬ìš©", value=True)
    with ec3: warmup = st.number_input("ì›Œë°ì—… ì¿¼ë¦¬ ìˆ˜", min_value=0, max_value=10, value=2, step=1)
    if st.button("í‰ê°€ ì‹¤í–‰", use_container_width=True):
        if not up:
            st.warning("eval.jsonl íŒŒì¼ì„ ì—…ë¡œë“œí•´ ì£¼ì„¸ìš”.")
        else:
            items = _load_eval_jsonl(up)
            if not items:
                st.error("ìœ íš¨í•œ í•­ëª©ì´ ì—†ìŠµë‹ˆë‹¤. ê° ì¤„ì€ {'query':..., 'gold_id' ë˜ëŠ” 'gold_ids': [...]} í˜•ì‹ì´ì–´ì•¼ í•©ë‹ˆë‹¤.")
            else:
                # ì›Œë°ì—… í˜¸ì¶œë¡œ ì§€ì—° ì•ˆì •í™”
                for it in items[:int(warmup)]:
                    try:
                        httpx.get(f"{API}/search",
                                  params={"q": it['query'], "k": ek, "rerank": str(ererank).lower(), "cand_factor": cand_factor},
                                  timeout=60)
                    except Exception:
                        pass
                rows, lats = [], []
                with st.spinner("í‰ê°€ ì¤‘..."):
                    for it in items:
                        t0 = time.perf_counter()
                        r = httpx.get(
                            f"{API}/search",
                            params={"q": it['query'], "k": ek, "rerank": str(ererank).lower(), "cand_factor": cand_factor},
                            timeout=120,
                        ).json()
                        ms = (time.perf_counter() - t0) * 1000.0
                        lats.append(ms)
                        pred_ids = [h["id"] for h in r.get("results", [])]
                        rows.append({
                            "query": it["query"],
                            "gold_ids": ", ".join(it["gold_ids"]),
                            f"nDCG@{int(ek)}": _ndcg_at_k(pred_ids, it["gold_ids"], k=int(ek)),
                            f"MRR@{int(ek)}":  _mrr_at_k(pred_ids, it["gold_ids"], k=int(ek)),
                            f"Recall@{int(ek)}": _recall_at_k(pred_ids, it["gold_ids"], k=int(ek)),
                            "latency_ms": ms,
                            "pred_ids": ", ".join(pred_ids),
                        })
                # ìš”ì•½ ë©”íŠ¸ë¦­
                def _avg(xs): return sum(xs)/len(xs) if xs else 0.0
                df = pd.DataFrame(rows)
                ndcg_avg = float(_avg(df[f"nDCG@{int(ek)}"].tolist()))
                mrr_avg  = float(_avg(df[f"MRR@{int(ek)}"].tolist()))
                rec_avg  = float(_avg(df[f"Recall@{int(ek)}"].tolist()))
                p95_ms   = float(_p95(lats))
                avg_ms   = float(_avg(lats))
                m1,m2,m3,m4,m5 = st.columns(5)
                m1.metric(f"nDCG@{int(ek)}", f"{ndcg_avg:.4f}")
                m2.metric(f"MRR@{int(ek)}",  f"{mrr_avg:.4f}")
                m3.metric(f"Recall@{int(ek)}", f"{rec_avg:.4f}")
                m4.metric("P95 Latency (ms)", f"{p95_ms:.1f}")
                m5.metric("Avg Latency (ms)", f"{avg_ms:.1f}")
                # ìƒì„¸ í…Œì´ë¸” & ì§€ì—° ì°¨íŠ¸
                st.markdown("#### ê°œë³„ ì§ˆì˜ë³„ ê²°ê³¼")
                st.dataframe(df, use_container_width=True, height=380)
                st.markdown("#### ì§€ì—°(ë°€ë¦¬ì´ˆ) ë¶„í¬")
                st.bar_chart(pd.DataFrame({"latency_ms": df["latency_ms"]}))

    with st.expander("ì§€í‘œ ì„¤ëª…"):
        st.markdown(f"""
- **nDCG@{int(ek)}**: ìƒìœ„ {int(ek)}ê°œ ìˆœìœ„ì—ì„œ ì •ë‹µì´ ì–¼ë§ˆë‚˜ ìœ„ì— ë°°ì¹˜ë˜ì—ˆëŠ”ì§€(ë¡œê·¸ í• ì¸). 1.0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ì¢‹ìŒ.
- **MRR@{int(ek)}**: ì²« ì •ë‹µì˜ ì—­ìˆœìœ„ í‰ê· (1ë“±=1.0, 5ë“±=0.2). ì •ë‹µì„ ëª‡ ë²ˆì§¸ì—ì„œ ì°¾ëŠ”ì§€ì˜ ì§ê´€ ì§€í‘œ.
- **Recall@{int(ek)}**: ìƒìœ„ {int(ek)}ê°œ ì•ˆì— ì •ë‹µì´ í•œ ë²ˆì´ë¼ë„ í¬í•¨ë˜ì—ˆëŠ”ì§€(íšŒìˆ˜ìœ¨).
- **P95 latency**: ì „ì²´ ìš”ì²­ ì¤‘ 95%ê°€ ì´ ì‹œê°„ ì´ë‚´ì— ëë‚¬ìŒì„ ì˜ë¯¸(ìµœì•…ì— ê°€ê¹Œìš´ ì§€ì—°).
        """)
# =======================================================================
